{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Model complexity\n",
    "\n",
    "Maxim Panov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "sns.set()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Polynomial example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def f_poly(x, coefs):\n",
    "    summands = [x**(power+1) * coef for power, coef in enumerate(coefs)]\n",
    "    return np.array(summands).sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "poly_coefs = [1, -0.5, -1, 0.6]\n",
    "noise_std = 0.1\n",
    "\n",
    "X = np.random.rand(20, 1) * 2 - 1\n",
    "y = f_poly(X, poly_coefs)\n",
    "y += np.random.randn(*y.shape) * noise_std\n",
    "\n",
    "X_test = np.linspace(-1, 1, 100)[:, np.newaxis]\n",
    "y_noiseless = f_poly(X_test, poly_coefs)\n",
    "y_test = y_noiseless + np.random.randn(*y_noiseless.shape) * noise_std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(X_test, y_noiseless);\n",
    "plt.plot(X, y, '.r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### A pipeline for a polynomial fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "def plot_results(y_pred):\n",
    "    plt.plot(X_test, y_noiseless)\n",
    "    plt.plot(X_test, y_pred, '--g')\n",
    "    plt.plot(X, y, '.r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "model = make_pipeline(PolynomialFeatures(), Ridge())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### TODO: fit the model & plot predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "model.fit(X, y)\n",
    "y_pred = model.predict(X_test)\n",
    "plot_results(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### TODO: \n",
    "- import mean square error from sklearn.metrics.regression\n",
    "- estimate accuracy of the prediction on\n",
    "  * the train set\n",
    "  * the test set\n",
    "  * the noiseless version of the test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.regression import mean_squared_error as mse\n",
    "\n",
    "print(mse(y, model.predict(X)))\n",
    "print(mse(y_test, model.predict(X_test)))\n",
    "print(mse(y_noiseless, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bias Variance Decomposition\n",
    "\n",
    "Expected test error for different variations of the *training data* sampled from, $\\Pr(\\mathbf{x}, y)$\n",
    "\n",
    "$$\\mathbb{E}\\left[ (y - \\hat{f}(\\mathbf{x}))^2 \\right].$$\n",
    "\n",
    "Decompose as\n",
    "\n",
    "$$\\mathbb{E}\\left[ (y - \\hat{f}(\\mathbf{x}))^2 \\right] = \\text{bias}\\left[\\hat{f}(\\mathbf{x})\\right]^2 + \\text{variance}\\left[\\hat{f}(\\mathbf{x})\\right] +\\sigma^2.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bias\n",
    "\n",
    "- Given by\n",
    "    $$\\text{bias}\\left[\\hat{f}(\\mathbf{x})\\right] = \\mathbb{E}\\left[\\hat{f}(\\mathbf{x})\\right] - f(\\mathbf{x}).$$\n",
    "    \n",
    "- Error due to bias comes from a model that's too simple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Variance\n",
    "\n",
    "- Given by\n",
    "    $$\\text{variance}\\left[\\hat{f}(\\mathbf{x})\\right] = \\mathbb{E}\\left[\\left(\\hat{f}(\\mathbf{x}) -  \\mathbb{E}\\left[\\hat{f}(\\mathbf{x})\\right]\\right)^2\\right].$$\n",
    "    \n",
    "- Slight variations in the training set cause changes in the prediction. Error due to variance is error in the model due to an overly complex model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bias-variance tradeoff\n",
    "\n",
    "<div style=\"width:100%; text-align:center\">\n",
    "<img src=http://scott.fortmann-roe.com/docs/docs/BiasVariance/biasvariance.png width=500px>\n",
    "</div>\n",
    "\n",
    "Check a great tutorial http://scott.fortmann-roe.com/docs/BiasVariance.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem:** high dimension of input.\n",
    "\n",
    "**Example:** in FMRI-based pattern recognition dimension of $\\mathbf{x}$ can easily be 20000.\n",
    "\n",
    "**Solution 1:** ridge regression\n",
    "$$\n",
    "  \\min_{\\mathbf{w}} \\sum_{i = 1}^N (y^i - \\mathbf{w}^T \\mathbf{x}^{i})^2 + \\lambda \\|\\mathbf{w}\\|_2^2.\n",
    "$$\n",
    "\n",
    "**Problem 2:** what if we want feature selection?\n",
    "\n",
    "**Solution 2:** LASSO\n",
    "$$\n",
    "  \\min_{\\mathbf{w}} \\sum_{i = 1}^N (y^i - \\mathbf{w}^T \\mathbf{x}^{i})^2 + \\lambda \\|\\mathbf{w}\\|_1,\n",
    "$$\n",
    "where $\\|\\mathbf{w}\\|_1 = \\sum_{j = 1}^p |w_j|$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Lasso vs Ridge regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<div style=\"width:60%; text-align:center\">\n",
    "<img src=https://1.bp.blogspot.com/-tXq6Nl2lcNg/V3qzttiZ4sI/AAAAAAAAN_M/6nmjgwydWJUy5Kqt9gFg2Nb12BCTcD4ogCLcB/s1600/LASSO.png>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### TODO: try different values of parameters (degree & alpha) and find the best possible fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### TODO:  Estimate errors for the best possible fit, compare its errors with the previous results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### TODO: set *alpha=1e-7*; calculate & plot three errors as functions of *degree*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "degree_range = range(1, 21) # 1, 2, ..., 20\n",
    "errors_train = []\n",
    "errors_test = []\n",
    "errors_test_noiseless = []\n",
    "for degree in degree_range:\n",
    "    model = ...\n",
    "    error = mse(...)\n",
    "    errors_train.append(error)\n",
    "    ...\n",
    "    \n",
    "plt.plot(degree_range, errors_train)\n",
    "plt.plot(degree_range, errors_test)\n",
    "plt.plot(degree_range, errors_test_noiseless)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### TODO: set degree=20 and try different regularization parameters alpha; plot the same lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Regression with Nearest Neighbours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 1-Nearest Neighbour\n",
    "* Keep the whole training dataset: ${(x, y)}$.\n",
    "* A query example (vector) $q$ comes\n",
    "* Find closest example(s) $x^*$.\n",
    "* Predict $y^*$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### K-Nearest Neighbours\n",
    "* **Problem:** one neighbour can give unstable predictions.\n",
    "* **Solution:** take $k$ nearest neighbours.\n",
    "* **Output**: just predict the average output among $k$ nearest neighbors.\n",
    "\n",
    "![image](./figures/knn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Nearest neighbours in Scikit learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = 5\n",
    "knn = KNeighborsRegressor(n_neighbors, weights=\"uniform\")\n",
    "knn.fit(X, y)\n",
    "y_ = knn.predict(X_test)\n",
    "\n",
    "plt.scatter(X, y, c='r', label='data')\n",
    "plt.plot(X_test, y_, c='g', label='prediction')\n",
    "plt.axis('tight')\n",
    "plt.legend()\n",
    "plt.title(\"KNeighborsRegressor (k = %i)\" % (n_neighbors))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: Approximation of Pressure Distribution on Airfoils\n",
    "\n",
    "In this example we demonstrate:\n",
    "    \n",
    "* Basic data loading and splitting\n",
    "* Construction of surrogate models with multiple inputs/outputs\n",
    "* Basic analysis of results\n",
    "\n",
    "__Notes__:\n",
    "\n",
    "* Approximation is based on real database of airfoils\n",
    "* We seek to approximate the pressure distribution givean an airfoil shape\n",
    "* One can also solve inverse problem (i.e. approximate airfoil shape give desired pressure distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "0) Imports\n",
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import gaussian_process, linear_model\n",
    "import utils as aux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1) Loading data\n",
    "\n",
    "__TODO__:\n",
    "\n",
    "* Specify path to data (approx_pressure_distribution_X57_Y57_)\n",
    "* Load the data into variable\n",
    "* Determine the shape of the data (**shape** command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2) Specify inputs / outputs\n",
    "\n",
    "__TODO__:\n",
    "\n",
    "* Put the first 57 columns to __inputs__\n",
    "* Put the last 57 columns to __outputs__\n",
    "* Ensure sizes of __inputs__ and __outputs__ are equal (not that everything starts from 0 in Python)\n",
    "* Split dataset to test and train: __train_x__, __train_y__, __test_x__, __test_y__ (use any two airfoils for test)\n",
    "\n",
    "\n",
    "_Hint: To split the dataset you need to perform slicing like X[:, :10] - which means that you take all rows and 10 first columns from X_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 3) Build regression model\n",
    "\n",
    "__TODO__:\n",
    "\n",
    "* Create sklearn model for least squares estimation\n",
    "* Create model using __fit__ function\n",
    "* Try ridge regression and play with regularization parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 4) Calculate errors on test set\n",
    "\n",
    "__TODO__:\n",
    "\n",
    "* Calculate mean absolute error on the __train_x__, __train_y__\n",
    "* Calculate mean absolute error on the __test_x__, __test_y__\n",
    "\n",
    "*Hint: Use abs and mean commands of numpy*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 5) Visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "aux.airfoil_plotting(test_x, test_y, model.predict(test_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 6) Optional\n",
    "\n",
    "__TODO__:\n",
    "\n",
    "* Change approximation technique\n",
    "* Exchange inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 7) Approximation of artificial data generated by branin function:\n",
    "\n",
    "* $$f(x_1, x_2) = (x_2 - a  x_1^2 +  b x_1 - c)^2 +  d \\cos(x_1) + e;$$\n",
    "* $$x_1 \\in [-5, 10], x_2 \\in [0, 15];$$\n",
    "* $$a = 5.1 / 4 / \\pi^2;$$\n",
    "* $$b = 5 / \\pi;$$\n",
    "* $$c = 6;$$\n",
    "* $$d = 10 (1 - 1 / 8 / \\pi);$$\n",
    "* $$e = 10.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__TODO__:\n",
    "\n",
    "* Construct approximation with linear and nonlinear technique\n",
    "* Compare results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [conda env:py3]",
   "language": "python",
   "name": "conda-env-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
